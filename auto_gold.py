# auto_gold.py â€” ORQUESTADOR EXTERNO AUREN AUTO GOLD
# Llama (directa o indirectamente) a:
# - MIND ENGINE  â†’ descubre topics calientes (local)
# - AUREN-API-HUB:
#       /topic_money_flow   (EMPIRE SCALER)
#       /media_plan         (MEDIA FACTORY)
#       /quality_analyze    (QUALITY ENGINE)
# - AUREN-CREATIVE-ENGINE  â†’ genera el guion PRO (si falla â†’ fallback local)
# - AUREN AGENTS (Groq)     â†’ Angle Master, Script Doctor, Clip Splitter, etc.
#
# Se ejecuta fuera de Hugging (GitHub Actions o tu PC).

import os
import json
from typing import List, Dict, Any

from gradio_client import Client
import requests  # ğŸ‘ˆ para Pexels / Pixabay
from agents.topic_scout import discover_hot_seeds
from agents.channel_router import pick_next_job
from topic_memory import mark_used
from auren_brain_adapter import load_brain_plan, pick_video_from_brain
from vault.vault_media import load_vault, suggest_offer_for_video

# ==============================
# IMPORT: AUREN AGENTS (carpeta /agents)
# ==============================

# ------------- FÃBRICA (CREATIVE + FINAL) -------------
from agents.angle_master import run_agent as run_angle_master
from agents.script_doctor import run_agent as run_script_doctor
from agents.clip_splitter import run_agent as run_clip_splitter
from agents.title_lab import run_agent as run_title_lab
from agents.platform_translator import run_agent as run_platform_translator

# ------------- MONEY / AFILIADOS -------------
from agents.hotmart_engine import run_agent as run_hotmart_engine
from agents.saas_engine import run_agent as run_saas_engine

# ------------- CRECIMIENTO Y OPTIMIZACIÃ“N -------------
from agents.hook_engine import run_agent as run_hook_engine
from agents.novelty_detector import run_agent as run_novelty_detector
from agents.opportunity_scorer import run_agent as run_opportunity_scorer
from agents.content_gap_hunter import run_agent as run_content_gap_hunter
from agents.hashtag_engine import run_agent as run_hashtag_engine
from agents.description_engine import run_agent as run_description_engine

from agents.upload_scheduler import run_agent as run_upload_scheduler
from agents.retention_analyzer import run_agent as run_retention_analyzer
from agents.ctr_forecaster import run_agent as run_ctr_forecaster
from agents.content_performance import run_agent as run_content_performance

# ------------- DASHBOARD -------------
from agents.dashboard_engine import run_agent as run_dashboard_engine

# ------------- **BRAIN (NUEVOS)** -------------
from agents.trend_oracle import run_agent as run_trend_oracle
from agents.channel_evaluator import run_agent as run_channel_evaluator

# ==============================
# MAPEOS DESDE AUREN BRAIN
# ==============================

def map_emotion(brain_emotion: str) -> str:
    """
    Traduce las etiquetas del Brain a algo que entiendan los agentes.
    """
    e = (brain_emotion or "").lower()

    if "miedo" in e:
        return "Miedo (suave)"
    if "aspiracional" in e:
        return "Aspiracional"
    if "calma" in e:
        return "Calma"
    if "rabia" in e:
        return "IndignaciÃ³n controlada"

    # fallback genÃ©rico
    return "Motivador"


def map_platform(brain_platform: str) -> str:
    """
    Traduce 'tiktok', 'shorts', 'reels' â†’ nombre amigable para el pipeline.
    """
    p = (brain_platform or "").lower()

    if "tiktok" in p:
        return "TikTok"
    if "short" in p:
        return "YouTube Shorts"
    if "reel" in p:
        return "Instagram Reels"

    # fallback: formato vertical corto por defecto
    return "YouTube Shorts"

# ==============================
# CONFIG: IDs de tus Spaces
# ==============================

HUB_SPACE_ID = os.getenv("AUREN_HUB_SPACE_ID", "Mariapc601/AUREN-API-HUB").strip()
CREATIVE_SPACE_ID = os.getenv("AUREN_CREATIVE_SPACE_ID", "Mariapc601/AUREN-CREATIVE-ENGINE").strip()
# Render Server (cola de vÃ­deo)
RENDER_URL = os.getenv(
    "AUREN_RENDER_URL",
    "https://mariapc601-auren-render-server.hf.space/render_video",  # por defecto tu Space
).strip()

# Si tus Spaces son privados, usamos HF_TOKEN del entorno.
HF_TOKEN = os.getenv("HF_TOKEN", "").strip()


def get_client(space_id: str) -> Client:
    """
    Crea un cliente gradio_client para un Space.
    Si existe HF_TOKEN, lo dejamos en la variable de entorno
    (gradio_client la usa internamente).
    """
    if HF_TOKEN:
        os.environ["HF_TOKEN"] = HF_TOKEN
    return Client(space_id)

# ============================================================
# WRAPPER para AUREN-CREATIVE-ENGINE (Space remoto)
# ============================================================

def run_creative_engine(params: dict) -> str:
    """
    Wrapper que llama al Space AUREN-CREATIVE-ENGINE
    y se asegura de que SIEMPRE haya un 'audience' vÃ¡lido.
    """
    audience = params.get(
        "audience",
        "jÃ³venes 18-30 aÃ±os de EspaÃ±a que quieren dinero y libertad usando IA y negocios online"
    )

    payload = {
        "topic": params["topic"],
        "emotion": params["emotion"],
        "platform": params["platform"],
        "audience": audience,
    }

    client = get_client(CREATIVE_SPACE_ID)

    # IMPORTANTE: aquÃ­ pasamos los 4 argumentos que espera el Space
    result = client.predict(
        payload["topic"],
        payload["emotion"],
        payload["platform"],
        payload["audience"],
    )

    if isinstance(result, str):
        return result
    return str(result)

# ============================================================
# 1) MIND ENGINE â€” descubrir topics a partir de un NICHO
#    (implementado localmente aquÃ­, sin llamar a ningÃºn Space)
# ============================================================

def mind_discover_topics(
    niche: str,
    country_code: str = "ES",
    lang: str = "es",
    n: int = 7,
) -> Dict[str, Any]:
    """
    Genera una lista de topics a partir de un NICHO.
    Esto simula tu AUREN-MIND-ENGINE pero en versiÃ³n local.
    Devuelve:
      {
        "topics": [str, ...],
        "markdown": str  # bloque bonito para meter en el informe
      }
    """
    base = niche.strip()
    if not base:
        base = "dinero y libertad"

    templates = [
        f"{base} para principiantes",
        f"Errores tÃ­picos en {base}",
        f"CÃ³mo ganar dinero con {base}",
        f"{base} explicado a niÃ±os de 12 aÃ±os",
        f"Los mayores mitos sobre {base}",
        f"Historias reales de gente que cambiÃ³ su vida gracias a {base}",
        f"{base} en {country_code}: oportunidades ocultas",
    ]

    topics = templates[: max(1, min(n, len(templates)))]

    # Bloque markdown para el informe
    md = [
        "# ğŸ§  AUREN MIND ENGINE â€” Discover hot topics",
        "",
        f"**Nicho:** {base}",
        "",
        f"**PaÃ­s objetivo:** {country_code}  |  **Idioma:** {lang}",
        "",
        "",
        "## ğŸ¯ Temas sugeridos",
        "",
    ]
    for i, t in enumerate(topics, start=1):
        md.append(f"**{i}. {t}**")
        md.append(f"- Enfoque: explica {base} con ejemplos muy cercanos al pÃºblico objetivo.")
        md.append("")

    return {"topics": topics, "markdown": "\n".join(md)}


# ============================================================
# 2) EMPIRE SCALER â€” money_score via HUB (/topic_money_flow)
# ============================================================

def hub_topic_money_flow(topics: List[str], lang: str = "es") -> List[Dict[str, Any]]:
    """
    Llama al endpoint /topic_money_flow del HUB y devuelve SIEMPRE una lista de dicts.
    Cada dict incluye: topic, views_30d, intent, ads_density, money_score.
    """
    client = get_client(HUB_SPACE_ID)
    topics_json = json.dumps(topics, ensure_ascii=False)

    result = client.predict(
        topics_json,
        lang,
        api_name="/topic_money_flow",
    )

    # HUB actual devuelve lista directa
    if isinstance(result, list):
        return result

    # Por si en el futuro volvemos a {"results": [...]}
    if isinstance(result, dict) and isinstance(result.get("results"), list):
        return result["results"]

    raise RuntimeError(
        f"Respuesta inesperada de topic_money_flow: tipo {type(result)} | contenido: {str(result)[:200]}"
    )


# ============================================================
# 3) MEDIA FACTORY â€” plan de miniatura + B-roll via HUB
# ============================================================

def hub_media_plan(script: str, want_thumb: bool, want_broll: bool) -> Dict[str, Any]:
    """
    Llama al endpoint /media_plan del HUB y normaliza la salida.
    Devuelve dict:
    {
      "plan": str | None,
      "thumbnail_plan": str | None,
      "broll_plan": str | None,
      "raw": respuesta_original
    }
    """
    client = get_client(HUB_SPACE_ID)
    result = client.predict(
        script.strip(),
        bool(want_thumb),
        bool(want_broll),
        api_name="/media_plan",
    )

    # String plano
    if isinstance(result, str):
        return {
            "plan": result,
            "thumbnail_plan": None,
            "broll_plan": None,
            "raw": result,
        }

    # Dict estructurado
    if isinstance(result, dict):
        plan = result.get("plan")
        thumb = result.get("thumbnail_plan")
        broll = result.get("broll_plan")

        if not any([plan, thumb, broll]):
            txt = json.dumps(result, ensure_ascii=False, indent=2)
            return {
                "plan": txt,
                "thumbnail_plan": None,
                "broll_plan": None,
                "raw": result,
            }

        return {
            "plan": plan,
            "thumbnail_plan": thumb,
            "broll_plan": broll,
            "raw": result,
        }

    # Tipo raro
    return {
        "plan": f"âš ï¸ Respuesta inesperada de /media_plan: {type(result)} | {str(result)[:200]}",
        "thumbnail_plan": None,
        "broll_plan": None,
        "raw": result,
    }


# ============================================================
# 4) QUALITY ENGINE â€” anÃ¡lisis via HUB (/quality_analyze)
# ============================================================

def hub_quality_analyze(script: str, tipo: str) -> Dict[str, Any]:
    """
    Llama al endpoint /quality_analyze del HUB y normaliza la salida.
    Devuelve dict:
    {
      "informe": str | None,
      "metrics": dict,
      "sentiment": dict,
      "suggestions": list[str]
    }
    """
    client = get_client(HUB_SPACE_ID)
    result = client.predict(
        script,
        tipo,
        api_name="/quality_analyze",
    )

    if isinstance(result, str):
        return {
            "informe": result,
            "metrics": {},
            "sentiment": {},
            "suggestions": [],
        }

    if isinstance(result, dict):
        return {
            "informe": result.get("informe"),
            "metrics": result.get("metrics", {}) or {},
            "sentiment": result.get("sentiment", {}) or {},
            "suggestions": result.get("suggestions", []) or [],
        }

    return {
        "informe": f"âš ï¸ Respuesta inesperada de /quality_analyze: {type(result)} | {str(result)[:200]}",
        "metrics": {},
        "sentiment": {},
        "suggestions": [],
    }


# ============================================================
# 5) CREATIVE ENGINE â€” guion V1 (Space + fallback local)
# ============================================================

def creative_generate_script(topic: str, emotion: str, platform: str, audience: str | None = None) -> str:
    """
    Intenta llamar al Space AUREN-CREATIVE-ENGINE.
    Si falla, usa fallback local.
    """

    # fallback de audiencia si viene vacÃ­a
    if not audience or audience.strip() == "":
        audience = "jÃ³venes 18-30 aÃ±os de EspaÃ±a que quieren dinero y libertad usando IA y negocios online"

    # 1) Intento normal: Space remoto
    if CREATIVE_SPACE_ID:
        try:
            result = run_creative_engine({
                "topic": topic,
                "emotion": emotion,
                "platform": platform,
                "audience": audience,
            })
            return result

        except Exception as e:
            # Log tÃ©cnico solo en consola, no en el guion
            print(f"âš ï¸ Error llamando a AUREN-CREATIVE-ENGINE ({CREATIVE_SPACE_ID}):", e)

    # 2) FALLBACK LOCAL â€” Guion limpio y usable
    hook = (
        f"Nadie te explicÃ³ de verdad quÃ© es {topic}, pero cada dÃ­a que no entiendes esto,"
        " alguien gana dinero a tu costa."
    )

    script = f"""ğŸ§  AUREN-CREATIVE-ENGINE (FALLBACK LOCAL)

{hook}

Mira, {topic} no va de hacerte rico rÃ¡pido, va de entender un sistema nuevo de dinero que ya estÃ¡ aquÃ­ aunque hagas como que no existe.

Primero, lo simple: te explico en palabras normales quÃ© es y quÃ© no es {topic}, sin tecnicismos ni humo.

Luego, los errores que comete todo principiante: entrar por hype, invertir lo que no tiene y seguir consejos de gente que ni enseÃ±a su cara.

DespuÃ©s, la parte Ãºtil: 2â€“3 pasos concretos para empezar sin arruinarte, con cantidades pequeÃ±as y reglas claras.

Y despuÃ©s, la verdad incÃ³moda: si no entiendes cÃ³mo funciona el juego del dinero, siempre juegas en el equipo que pierde.

AsÃ­ que la prÃ³xima vez que escuches {topic}, no huyas: respira hondo, entiende las reglasâ€¦ y juega a tu favor.
"""

    return script


# ============================================================
# 6) DESCARGA AUTOMÃTICA DE CLIPS (PEXELS / PIXABAY)
# ============================================================

def download_video(url: str, save_path: str):
    """Descarga un archivo de vÃ­deo desde una URL a la ruta indicada."""
    try:
        r = requests.get(url, stream=True, timeout=10)
        r.raise_for_status()
        with open(save_path, "wb") as f:
            for chunk in r.iter_content(chunk_size=8192):
                f.write(chunk)
        return True
    except Exception as e:
        print(f"âš ï¸ Error descargando {url}: {e}")
        return False


def extract_keywords_from_plan(plan: str) -> list[str]:
    """
    Extrae palabras clave del plan de B-roll automÃ¡ticamente.
    Busca palabras relevantes (dinero, estrÃ©s, oficina, Ã©xitoâ€¦)
    """
    import re
    words = re.findall(r"[a-zA-ZÃ¡Ã©Ã­Ã³ÃºÃ±ÃÃ‰ÃÃ“ÃšÃ‘]{4,}", plan.lower())

    blacklist = {"porque", "cuando", "donde", "sobre", "segÃºn", "video", "broll", "miniatura"}
    keywords = [w for w in words if w not in blacklist]

    # Ãštiles como bÃºsqueda
    return list(set(keywords))[:10]   # mÃ¡ximo 10


def pexels_search_and_download(keywords: list[str], target_folder: str, max_videos: int = 5):
    api_key = os.getenv("PEXELS_API_KEY", "")
    if not api_key:
        print("âš ï¸ No PEXELS_API_KEY en GitHub Secrets")
        return []

    headers = {"Authorization": api_key}
    saved_files = []

    for kw in keywords:
        url = f"https://api.pexels.com/videos/search?query={kw}&per_page=2"
        try:
            r = requests.get(url, headers=headers, timeout=10)
            data = r.json()
            for video in data.get("videos", []):
                file_url = video["video_files"][0]["link"]
                file_name = f"{kw}_{video['id']}.mp4"
                file_path = os.path.join(target_folder, file_name)
                if download_video(file_url, file_path):
                    saved_files.append(file_path)
                if len(saved_files) >= max_videos:
                    return saved_files
        except Exception:
            pass

    return saved_files


def pixabay_search_and_download(keywords: list[str], target_folder: str, max_videos: int = 5):
    api_key = os.getenv("PIXABAY_API_KEY", "")
    if not api_key:
        print("âš ï¸ No PIXABAY_API_KEY en GitHub Secrets")
        return []

    saved_files = []

    for kw in keywords:
        url = f"https://pixabay.com/api/videos/?key={api_key}&q={kw}&per_page=2"
        try:
            r = requests.get(url, timeout=10)
            data = r.json()
            for hit in data.get("hits", []):
                file_url = hit["videos"]["medium"]["url"]
                file_name = f"{kw}_{hit['id']}.mp4"
                file_path = os.path.join(target_folder, file_name)
                if download_video(file_url, file_path):
                    saved_files.append(file_path)
                if len(saved_files) >= max_videos:
                    return saved_files
        except Exception:
            pass

    return saved_files

# ============================================================
# 7) RENDER SERVER â€” Encola el vÃ­deo en el Space de render
# ============================================================

def send_to_render_server(
    template_id: str,
    script_v2: str,
    platform: str,
    language: str = "es",
    audience: str | None = None,
) -> Dict[str, Any]:
    if not RENDER_URL:
        return {
            "status": "disabled",
            "message": "AUREN_RENDER_URL no estÃ¡ configurado en el entorno.",
        }

    plat = (platform or "").lower()
    if any(x in plat for x in ["short", "tiktok", "reel", "vertical"]):
        aspect_ratio = "9:16"
        resolution = "1080x1920"
    else:
        aspect_ratio = "16:9"
        resolution = "1920x1080"

    scenes = [
        {
            "type": "talking_head",
            "duration": 60.0,
            "text": script_v2[:4000],
        }
    ]

    payload = {
        "template_id": template_id,
        "aspect_ratio": aspect_ratio,
        "resolution": resolution,
        "fps": 30,
        "language": language,
        "voice_profile": "auren_default_female",
        "audience": audience,
        "platform": platform,
        "scenes": scenes,
        "music": {
            "mood": "motivational",
            "intensity": "medium",
        },
    }

    try:
        r = requests.post(RENDER_URL, json=payload, timeout=20)
        r.raise_for_status()

        # Intentar parsear JSON; si no, devolver texto crudo
        try:
            data = r.json()
        except Exception:
            data = {
                "status": "ok_raw",
                "raw_text": r.text[:500],  # primeros 500 chars para inspecciÃ³n
            }

        data.setdefault("render_url", RENDER_URL)
        return data

    except Exception as e:
        return {
            "status": "error",
            "render_url": RENDER_URL,
            "error": str(e),
        }



# ============================================================
# 8) PIPELINE GOLD COMPLETO (ya con AGENTES AUREN)
# ============================================================
def run_gold_pipeline(
    niche: str,
    country_code: str = "ES",
    lang_topics: str = "es",
    emotion: str = "Motivador",
    platform: str = "YouTube Shorts",
    want_thumb: bool = True,
    want_broll: bool = True,
    run_quality: bool = True,
    top_n: int = 1,
    channel_name: str | None = None,
    affiliate_slot: str | None = None,
) -> str:
    """
    1) MIND: genera lista de topics a partir de un NICHO.
    2) EMPIRE: calcula money_score para cada topic (HUB /topic_money_flow).
    3) Ordena descendente por money_score.
    4) Para los TOP N:
       - Genera Ã¡ngulos (AUREN_ANGLE_MASTER + HOOK_ENGINE).
       - Llama a CREATIVE (guion V1).
       - Refinado (AUREN_SCRIPT_DOCTOR â†’ guion V2).
       - Analiza retenciÃ³n (RETENTION_ANALYZER).
       - Crea clips (AUREN_CLIP_SPLITTER).
       - TÃ­tulos (AUREN_TITLE_LAB).
       - TraducciÃ³n por plataforma (AUREN_PLATFORM_TRANSLATOR).
       - DescripciÃ³n + hashtags (DESCRIPTION_ENGINE + HASHTAG_ENGINE).
       - Hotmart + SaaS (AUREN_HOTMART_ENGINE + AUREN_SAAS_ENGINE + VAULT si existe).
       - Llama a HUB /media_plan (miniatura + B-roll) con guion V2.
       - PredicciÃ³n de CTR (CTR_FORECASTER).
       - Llama a HUB /quality_analyze (QA) con guion V2.
       - Descarga clips de apoyo (Pexels / Pixabay).
       - Plan de publicaciÃ³n (UPLOAD_SCHEDULER).
    Devuelve un markdown grande con todo + dashboard final.
    """

    # 1) MIND â€” descubrir topics
    mind = mind_discover_topics(niche, country_code=country_code, lang=lang_topics)
    topics = mind["topics"]

    if not topics:
        return "âš ï¸ MIND ENGINE no generÃ³ topics."

    # 2) EMPIRE â€” money score
    money_rows = hub_topic_money_flow(topics, lang=lang_topics)

    fused = []
    for topic, row in zip(topics, money_rows):
        ms = float(row.get("money_score", 0.0) or 0.0)
        fused.append(
            {
                "topic": topic,
                "views_30d": int(row.get("views_30d", 0) or 0),
                "intent": float(row.get("intent", 0.0) or 0.0),
                "ads_density": float(row.get("ads_density", 0.0) or 0.0),
                "money_score": ms,
            }
        )

    fused.sort(key=lambda x: x["money_score"], reverse=True)
    top_n = max(1, min(top_n, len(fused)))
    top_topics = fused[:top_n]

    out: List[str] = []

    out.append("# ğŸŸ£ AUREN AUTO GOLD â€” RUN EXTERNO\n")
    out.append(
        "Este script se ejecuta **fuera de HuggingFace** y orquesta:\n"
        "- MIND ENGINE (topics calientes)\n"
        "- EMPIRE SCALER (money_score vÃ­a HUB)\n"
        "- CREATIVE ENGINE (guion V1)\n"
        "- AUREN AGENTS (guion V2, hooks, clips, tÃ­tulos, afiliados)\n"
        "- MEDIA FACTORY (miniatura + B-roll vÃ­a HUB)\n"
        "- QUALITY ENGINE (QA vÃ­a HUB)\n"
        "- RENDER SERVER (cola lÃ³gica de vÃ­deo)\n"
    )

    # ğŸ” Contexto de ejecuciÃ³n (canal + slot de afiliado)
    if channel_name or affiliate_slot:
        out.append("\n## ğŸ§© Contexto de ejecuciÃ³n\n")
        if channel_name:
            out.append(f"- Canal: **{channel_name}**")
        if affiliate_slot:
            out.append(f"- Affiliate slot: **{affiliate_slot}**")

    # Bloque MIND
    out.append("\n## ğŸ§  MIND ENGINE â€” Discover hot topics\n")
    out.append("```markdown")
    out.append(mind["markdown"])
    out.append("```")

    # =========================================
    # EXTRA MIND: NOVELTY + OPORTUNIDADES + GAPS
    # =========================================
    topics_list_markdown = "\n".join(f"- {t}" for t in topics)

    out.append("\n### ğŸ§  Extra MIND â€” anÃ¡lisis de novedad y oportunidades\n")

    # NOVELTY DETECTOR
    novelty_data = run_novelty_detector(
        {
            "topics_raw": topics_list_markdown,
        }
    )
    novelty_raw = novelty_data.get("novelty_report_raw", "").strip()

    # OPPORTUNITY SCORER
    opportunity_data = run_opportunity_scorer(
        {
            "topics_raw": topics_list_markdown,
        }
    )
    opportunity_raw = opportunity_data.get("opportunity_table_raw", "").strip()

    # CONTENT GAP HUNTER
    gap_data = run_content_gap_hunter(
        {
            "niche": niche,
            "competitor_notes": "Competencia tÃ­pica de YouTube/TikTok en este nicho.",
        }
    )
    gaps_raw = gap_data.get("gaps_raw", "").strip()

    out.append("```markdown")
    out.append("#### NOVEDAD Y SATURACIÃ“N\n")
    out.append(novelty_raw or "âš ï¸ No se pudo generar anÃ¡lisis de novedad.")
    out.append("\n\n#### OPORTUNIDADES POR TEMA\n")
    out.append(opportunity_raw or "âš ï¸ No se pudo generar tabla de oportunidades.")
    out.append("\n\n#### GAPS DE CONTENIDO\n")
    out.append(gaps_raw or "âš ï¸ No se detectaron gaps especÃ­ficos.")
    out.append("```")

    # Tabla ranking EMPIRE
    out.append("\n## ğŸ’° Ranking de topics por money_score\n")
    out.append("| # | Topic | Views 30d | Intent % | Ads % | Money Score |\n")
    out.append("|---|-------|-----------|----------|-------|-------------|\n")
    for i, r in enumerate(fused, start=1):
        out.append(
            f"| {i} | {r['topic']} | {r['views_30d']} | "
            f"{r['intent']:.1f} | {r['ads_density']:.1f} | {r['money_score']:.1f} |"
        )

    # Detalle de los TOP
    for idx, r in enumerate(top_topics, start=1):
        topic = r["topic"]
        audience = "jÃ³venes que quieren ganar dinero con IA, negocios online y productividad"

        out.append("\n---\n")
        out.append(f"## ğŸ”¥ TOP {idx} â€” {topic}\n")
        out.append(
            f"- Money Score: **{r['money_score']:.1f}** | "
            f"Intent: **{r['intent']:.1f}%** | Ads: **{r['ads_density']:.1f}%**\n"
        )

        # ==========================
        # AUREN_ANGLE_MASTER
        # ==========================
        out.append("### ğŸ¯ Ãngulos generados (AUREN_ANGLE_MASTER)\n")
        angles_data = run_angle_master(
            {
                "topic": topic,
                "audience": audience,
                "emotion": emotion,
                "platform": platform,
                "num_angles": 12,
            }
        )
        angles_text = angles_data.get("angles_raw", "").strip()
        out.append("```markdown")
        out.append(angles_text or "âš ï¸ No se generaron Ã¡ngulos.")
        out.append("```")

        # ==========================
        # HOOK ENGINE â€” hooks extra
        # ==========================
        out.append("\n### âš¡ Hooks extra (AUREN_HOOK_ENGINE)\n")
        hook_data = run_hook_engine(
            {
                "topic": topic,
                "audience": audience,
                "emotion": emotion,
                "platform": platform,
            }
        )
        hooks_raw = hook_data.get("hooks_raw", "").strip()
        out.append("```markdown")
        out.append(hooks_raw or "âš ï¸ No se pudieron generar hooks adicionales.")
        out.append("```")

        # ==========================
        # CREATIVE ENGINE â€” GUION V1
        # ==========================
        out.append("\n### ğŸ§  Guion V1 generado (AUREN-CREATIVE-ENGINE)\n")
        topic_with_angles = (
            f"{topic}\n\nÃngulos sugeridos:\n{angles_text}" if angles_text else topic
        )
        script_v1 = creative_generate_script(
            topic_with_angles,
            emotion,
            platform,
            audience=audience,
        )

        out.append("```markdown")
        out.append(script_v1)
        out.append("```")

        # ==========================
        # SCRIPT DOCTOR â€” GUION V2
        # ==========================
        out.append("\n### âœï¸ Guion V2 refinado (AUREN_SCRIPT_DOCTOR)\n")
        script_v2_dict = run_script_doctor(
            {
                "script_v1": script_v1,
                "emotion": emotion,
                "platform": platform,
                "audience": audience,
                "style_notes": "Tono profesional, cercano, elegante, energÃ­a Pendragon.",
            }
        )
        script_v2 = script_v2_dict.get("script_v2", script_v1)
        out.append("```markdown")
        out.append(script_v2)
        out.append("```")

        # ==========================
        # RETENTION ANALYZER
        # ==========================
        out.append("\n### ğŸ“ˆ RetenciÃ³n estimada (AUREN_RETENTION_ANALYZER)\n")
        retention_data = run_retention_analyzer(
            {
                "script_v2": script_v2,
            }
        )
        retention_raw = retention_data.get("retention_report_raw", "").strip()
        out.append("```markdown")
        out.append(retention_raw or "âš ï¸ No se generÃ³ informe de retenciÃ³n.")
        out.append("```")

        # ==========================
        # CLIP SPLITTER â€” CLIPS
        # ==========================
        out.append("\n### ğŸ¬ Clips generados (AUREN_CLIP_SPLITTER)\n")
        clips_dict = run_clip_splitter(
            {
                "script_v2": script_v2,
                "min_clips": 7,
                "max_clips": 12,
            }
        )
        clips_raw = clips_dict.get("clips_raw", "").strip()
        out.append("```markdown")
        out.append(clips_raw or "âš ï¸ No se pudieron generar clips.")
        out.append("```")

        # ==========================
        # TITLE LAB
        # ==========================
        out.append("\n### ğŸ·ï¸ TÃ­tulos sugeridos (AUREN_TITLE_LAB)\n")
        titles_dict = run_title_lab(
            {
                "clip_text": script_v2,
                "platform": platform,
            }
        )
        titles_raw = titles_dict.get("titles_raw", "").strip()
        out.append("```markdown")
        out.append(titles_raw or "âš ï¸ No se generaron tÃ­tulos.")
        out.append("```")

        # ==========================
        # PLATFORM TRANSLATOR
        # ==========================
        out.append("\n### ğŸŒ AdaptaciÃ³n por plataforma (AUREN_PLATFORM_TRANSLATOR)\n")
        platform_dict = run_platform_translator(
            {
                "clip_text": script_v2,
            }
        )
        platform_versions_raw = platform_dict.get("platform_versions_raw", "").strip()
        out.append("```markdown")
        out.append(
            platform_versions_raw
            or "âš ï¸ No se generaron versiones por plataforma."
        )
        out.append("```")

        # ==========================
        # DESCRIPTION ENGINE + HASHTAG ENGINE
        # ==========================
        out.append(
            "\n### ğŸ“ DescripciÃ³n y hashtags (AUREN_DESCRIPTION_ENGINE + AUREN_HASHTAG_ENGINE)\n"
        )

        desc_data = run_description_engine(
            {
                "script_v2": script_v2,
                "topic": topic,
                "niche": niche,
            }
        )
        description_raw = desc_data.get("description_raw", "").strip()

        hashtag_data = run_hashtag_engine(
            {
                "topic": topic,
                "niche": niche,
                "language": lang_topics,
            }
        )
        hashtags_raw = hashtag_data.get("hashtags_raw", "").strip()

        out.append("```markdown")
        out.append("#### DescripciÃ³n sugerida\n")
        out.append(description_raw or "âš ï¸ No se generÃ³ descripciÃ³n.")
        out.append("\n\n#### Hashtags sugeridos\n")
        out.append(hashtags_raw or "âš ï¸ No se generaron hashtags.")
        out.append("```")

        # ==========================
        # AFFILIATES: HOTMART + SaaS + VAULT
        # ==========================
        out.append(
            "\n### ğŸ’¸ Encaje de afiliados (AUREN_HOTMART_ENGINE + AUREN_SAAS_ENGINE + VAULT)\n"
        )

        # Hotmart
        hotmart_data = run_hotmart_engine(
            {
                "topic": topic,
                "audience": audience,
                "channel_name": channel_name,
                "affiliate_slot": affiliate_slot,
            }
        )
        hotmart_raw = hotmart_data.get("hotmart_suggestion_raw", "").strip()

        # SaaS
        saas_data = run_saas_engine(
            {
                "topic": topic,
                "audience": audience,
                "channel_name": channel_name,
                "affiliate_slot": affiliate_slot,
            }
        )
        saas_raw = saas_data.get("saas_suggestion_raw", "").strip()

        # VAULT (si existe run_affiliates_vault, lo usamos; si no, no rompemos nada)
        vault_raw = ""
        try:
            vault_data = run_affiliates_vault(
                {
                    "topic": topic,
                    "niche": niche,
                    "channel_name": channel_name,
                    "affiliate_slot": affiliate_slot,
                }
            )
            vault_raw = vault_data.get("vault_markdown", "").strip()
        except NameError:
            vault_raw = "âš ï¸ Auren Affiliates Vault aÃºn no estÃ¡ conectado en este entorno."

        out.append("```markdown")
        out.append("#### Hotmart\n")
        out.append(hotmart_raw or "âš ï¸ Sin sugerencia Hotmart.")
        out.append("\n\n#### SaaS recurrente\n")
        out.append(saas_raw or "âš ï¸ Sin sugerencia SaaS.")
        out.append("\n\n#### VAULT / Enlace final\n")
        out.append(vault_raw or "âš ï¸ Sin respuesta de VAULT.")
        out.append("```")

        # ==========================
        # MEDIA PLAN (con GUION V2)
        # ==========================
        out.append("\n### ğŸ¥ Plan de producciÃ³n (HUB /media_plan)\n")
        media = hub_media_plan(script_v2, want_thumb=want_thumb, want_broll=want_broll)
        if media.get("plan"):
            out.append(media["plan"])
        if want_thumb and media.get("thumbnail_plan"):
            out.append("\n#### ğŸ–¼ï¸ Bloque Miniatura\n")
            out.append(media["thumbnail_plan"])
        if want_broll and media.get("broll_plan"):
            out.append("\n#### ğŸ¬ Bloque B-Roll\n")
            out.append(media["broll_plan"])

            # ==========================
            #  DESCARGA AUTOMÃTICA DE CLIPS
            # ==========================
            assets_folder = f"videos/assets_{topic.replace(' ', '_')}"
            os.makedirs(assets_folder, exist_ok=True)

            # 1) Extraer keywords del plan de B-roll
            kw = extract_keywords_from_plan(media.get("broll_plan", ""))

            # 2) Descargar desde Pexels
            pex_files = pexels_search_and_download(kw, assets_folder)

            # 3) Descargar desde Pixabay
            pix_files = pixabay_search_and_download(kw, assets_folder)

            out.append("\n### ğŸï¸ Clips descargados automÃ¡ticamente\n")
            out.append(f"- Pexels: {len(pex_files)} vÃ­deos")
            out.append(f"- Pixabay: {len(pix_files)} vÃ­deos")

        # ==========================
        # CTR FORECASTER (tÃ­tulo + miniatura)
        # ==========================
        out.append("\n### ğŸ¯ PredicciÃ³n de CTR (AUREN_CTR_FORECASTER)\n")

        first_title = ""
        if titles_raw:
            for line in titles_raw.splitlines():
                line = line.strip()
                if line and not line.startswith(("#", "-", "*")):
                    first_title = line
                    break

        thumb_brief_text = media.get("thumbnail_plan") or media.get("plan") or ""

        ctr_data = run_ctr_forecaster(
            {
                "title": first_title,
                "thumbnail_brief": thumb_brief_text,
            }
        )
        ctr_raw = ctr_data.get("ctr_forecast_raw", "").strip()

        out.append("```markdown")
        out.append(ctr_raw or "âš ï¸ No se pudo estimar el CTR.")
        out.append("```")

        # ==========================
        # UPLOAD SCHEDULER
        # ==========================
        out.append(
            "\n### ğŸ—“ Plan de publicaciÃ³n recomendado (AUREN_UPLOAD_SCHEDULER)\n"
        )
        upload_plan = run_upload_scheduler(
            {
                "audience": audience,
                "timezone": "Europe/Madrid",
            }
        )
        upload_raw = upload_plan.get("upload_plan_raw", "").strip()

        out.append("```markdown")
        out.append(upload_raw or "âš ï¸ No se generÃ³ plan de publicaciÃ³n.")
        out.append("```")

        # ==========================
        # QUALITY ENGINE (sobre GUION V2)
        # ==========================
        if run_quality:
            if (
                "short" in platform.lower()
                or "tiktok" in platform.lower()
                or "reels" in platform.lower()
            ):
                tipo = "Short motivacional (rÃ¡pido)"
            elif "long" in platform.lower():
                tipo = "VÃ­deo largo storytelling"
            else:
                tipo = "VÃ­deo educativo"

            out.append(f"\n### ğŸ§ª AnÃ¡lisis de calidad (QUALITY ENGINE â€” {tipo})\n")
            q = hub_quality_analyze(script_v2, tipo)
            if q.get("informe"):
                out.append(q["informe"])

        # ==========================
        # RENDER SERVER â€” Encolar vÃ­deo
        # ==========================
        out.append("\n### ğŸ§© Render job (AUREN RENDER SERVER)\n")

        # Usamos la misma carpeta de assets que hemos llenado mÃ¡s arriba
        assets_folder = f"videos/assets_{topic.replace(' ', '_')}"

        render_res = send_to_render_server(
            template_id="motivacional_v1",
            script_v2=script_v2,
            platform=platform,
            language=lang_topics,
            audience=audience,
            assets_folder=assets_folder,
        )

        out.append("```json")
        out.append(json.dumps(render_res, ensure_ascii=False, indent=2))
        out.append("```")

    # ==========================
    # DASHBOARD ENGINE â€” resumen ejecutivo del run
    # ==========================
    full_markdown = "\n".join(out)

    # Limitamos el tamaÃ±o para no romper el lÃ­mite de tokens de Groq
    max_chars = 6000
    if len(full_markdown) > max_chars:
        dashboard_input = full_markdown[-max_chars:]
    else:
        dashboard_input = full_markdown

    dashboard_data = run_dashboard_engine(
        {
            "inputs_raw": dashboard_input,
        }
    )
    dashboard_raw = dashboard_data.get("dashboard_summary_raw", "").strip()

    out.append("\n---\n")
    out.append("## ğŸ“Š Resumen ejecutivo (AUREN_DASHBOARD_ENGINE)\n")
    out.append("```markdown")
    out.append(dashboard_raw or "âš ï¸ No se generÃ³ resumen ejecutivo.")
    out.append("```")

    return "\n".join(out)

def main():
    # Â¿Hay plan de Auren Brain?
    brain_plan_path = os.getenv("AUREN_BRAIN_PLAN_PATH", "").strip()

    if brain_plan_path:
        # ============================
        # ğŸ›ï¸ MODO CONTROLADO POR BRAIN
        # ============================
        plan = load_brain_plan(brain_plan_path)
        video_cfg = pick_video_from_brain(plan)

        if not video_cfg:
            print("âš ï¸ Auren Brain no devolviÃ³ ningÃºn vÃ­deo. Saliendo.")
            return

        print("ğŸ§  Auren Brain activo:")
        print("   Canal:", video_cfg["channel_name"])
        print("   Topic:", video_cfg["topic"])
        print("   Video ID:", video_cfg["video_id"])
        print("   EmociÃ³n:", video_cfg["emotion"])
        print("   Plataforma:", video_cfg["target_platform"])

        niche = video_cfg["topic"]
        country_code = video_cfg["country"]
        lang_topics = video_cfg["language"]

        emotion = map_emotion(video_cfg["emotion"])
        platform = map_platform(video_cfg["target_platform"])
        want_thumb = True
        want_broll = True
        run_quality = True
        top_n = 1

        # ğŸ”— Datos extra para VAULT / contexto
        channel_name = video_cfg["channel_name"]
        affiliate_slot = video_cfg.get("affiliate_slot")

        markdown = run_gold_pipeline(
            niche=niche,
            country_code=country_code,
            lang_topics=lang_topics,
            emotion=emotion,
            platform=platform,
            want_thumb=want_thumb,
            want_broll=want_broll,
            run_quality=run_quality,
            top_n=top_n,
            channel_name=channel_name,
            affiliate_slot=affiliate_slot,
        )

        # Opcional: aquÃ­ podrÃ­as pasar tambiÃ©n info del Brain al nombre del fichero
        from datetime import datetime
        ts = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")

        os.makedirs("outputs", exist_ok=True)
        md_path = f"outputs/auren_gold_{ts}.md"
        json_path = f"outputs/auren_gold_{ts}.json"

        with open(md_path, "w", encoding="utf-8") as f:
            f.write(markdown)

        with open(json_path, "w", encoding="utf-8") as f:
            f.write(json.dumps({"output": markdown}, ensure_ascii=False, indent=2))

        print(f"\nğŸ’¾ Guardado en: {md_path} y {json_path}")

        os.makedirs("videos", exist_ok=True)
        video_plan_path = f"videos/video_plan_{ts}.md"

        video_plan_content = (
            "# ğŸ¬ AUREN VIDEO PLAN\n\n"
            "## ğŸ“ Guion + ProducciÃ³n\n\n"
            f"{markdown}\n"
        )

        with open(video_plan_path, "w", encoding="utf-8") as f:
            f.write(video_plan_content)

        print(f"ğŸ“¦ Plan de vÃ­deo guardado en: {video_plan_path}")
        return

    # ============================
    # ğŸ” MODO ANTIGUO (AutoGold solo)
    # ============================
    seeds = discover_hot_seeds()
    job = pick_next_job(seeds)

    if not job:
        print("âš ï¸ No hay temas nuevos disponibles (todas las semillas ya se usaron).")
        return

    channel = job["channel"]
    seed = job["seed"]
    topic_slug = job["topic_slug"]

    print("ğŸ§  Canal seleccionado:", channel["name"])
    print("ğŸŒ± Semilla seleccionada:", seed.keyword)
    print("ğŸªª Topic slug:", topic_slug)

    niche = seed.keyword
    country_code = channel["country"]
    lang_topics = channel["language"]

    emotion = "Motivador"
    platform = "YouTube Shorts"
    want_thumb = True
    want_broll = True
    run_quality = True
    top_n = 1

    # ğŸ”— TambiÃ©n pasamos el nombre de canal al pipeline
    channel_name = channel["name"]

    markdown = run_gold_pipeline(
        niche=niche,
        country_code=country_code,
        lang_topics=lang_topics,
        emotion=emotion,
        platform=platform,
        want_thumb=want_thumb,
        want_broll=want_broll,
        run_quality=run_quality,
        top_n=top_n,
        channel_name=channel_name,
        affiliate_slot=None,
    )

    print(markdown)
    mark_used(channel["id"], topic_slug)

    os.makedirs("outputs", exist_ok=True)
    from datetime import datetime
    ts = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")

    md_path = f"outputs/auren_gold_{ts}.md"
    json_path = f"outputs/auren_gold_{ts}.json"

    with open(md_path, "w", encoding="utf-8") as f:
        f.write(markdown)

    with open(json_path, "w", encoding="utf-8") as f:
        f.write(json.dumps({"output": markdown}, ensure_ascii=False, indent=2))

    print(f"\nğŸ’¾ Guardado en: {md_path} y {json_path}")

    os.makedirs("videos", exist_ok=True)
    video_plan_path = f"videos/video_plan_{ts}.md"

    video_plan_content = (
        "# ğŸ¬ AUREN VIDEO PLAN\n\n"
            "## ğŸ“ Guion + ProducciÃ³n\n\n"
            f"{markdown}\n"
    )

    with open(video_plan_path, "w", encoding="utf-8") as f:
        f.write(video_plan_content)

    print(f"ğŸ“¦ Plan de vÃ­deo guardado en: {video_plan_path}")


if __name__ == "__main__":
    main()
